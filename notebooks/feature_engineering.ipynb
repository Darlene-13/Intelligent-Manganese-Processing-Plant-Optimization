{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Manganese Processing Plant Feature Engineering\n",
    "#### Advanced feature creation for ML optimization models\n",
    "\n",
    "#### AUTHOR: DARLENE WENDY NASIMIYU\n",
    "#### Purpose: Create powerful features for manganese processing optimization"
   ],
   "id": "870d51ca7d847d5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T08:49:46.270086Z",
     "start_time": "2025-10-07T08:49:46.255340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ],
   "id": "6102ea71b04c1724",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T08:49:48.455819Z",
     "start_time": "2025-10-07T08:49:48.438621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#----SETUP: Get absolute path ---\n",
    "BASE_DIR = os.path.dirname(os.getcwd()) # Current working directory of the notebook\n",
    "data_dir = os.path.join(BASE_DIR, 'data', 'synthetic')\n",
    "\n",
    "print(\"Using data directory:\", data_dir)"
   ],
   "id": "41d94e6bd90c4e93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data directory: /home/darlenewendie/PycharmProjects/Intelligent-Manganese-Processing-Plant-Optimization/data/synthetic\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T08:57:23.022167Z",
     "start_time": "2025-10-07T08:57:22.014638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----DEFINE DATASET FILES-------\n",
    "dataset_files = {\n",
    "    'ore_feed': 'manganese_ore_feed.csv',\n",
    "    'blended_ore': 'manganese_blended_ore_feed.csv',\n",
    "    'crushing': 'manganese_crushing_circuit.csv',\n",
    "    'separation': 'manganese_separation_circuit.csv',\n",
    "    'flotation': 'manganese_flotation_circuit.csv',\n",
    "    'dms': 'manganese_dms_circuit.csv',\n",
    "    'jigging':'manganese_jigging_circuit.csv',\n",
    "    'dewatering': 'manganese_dewatering_circuit.csv',\n",
    "    'equipment': 'manganese_equipment_health.csv',\n",
    "    'energy': 'manganese_energy_consumption.csv',\n",
    "}\n",
    "# Load all datasets\n",
    "datasets = {}\n",
    "for name, filename in dataset_files.items():\n",
    "    filepath  = os.path.join(data_dir, filename)\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, parse_dates=['timestamp'])\n",
    "        datasets[name] = df\n",
    "        print(f\" Loaded {name}: {len(df):,} records, {len(df.columns)} columns\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Could not find {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {name}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nTotal datasets loaded: {len(datasets)}\")\n",
    "print(f\"Total records: {sum(len(df) for df in datasets.values()):,}\")"
   ],
   "id": "5ee83316890667d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded ore_feed: 10,000 records, 11 columns\n",
      " Loaded blended_ore: 6,522 records, 11 columns\n",
      " Loaded crushing: 15,000 records, 9 columns\n",
      " Loaded separation: 12,000 records, 13 columns\n",
      " Loaded flotation: 12,000 records, 22 columns\n",
      " Loaded dms: 8,000 records, 16 columns\n",
      " Loaded jigging: 10,000 records, 16 columns\n",
      " Loaded dewatering: 8,000 records, 18 columns\n",
      " Loaded equipment: 8,000 records, 12 columns\n",
      " Loaded energy: 10,000 records, 30 columns\n",
      "\n",
      "Total datasets loaded: 10\n",
      "Total records: 99,522\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:37:44.893648Z",
     "start_time": "2025-10-07T09:37:44.886826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#INITIALIZING AN EMPTY DICTIONARY FOR ENGINEERED DATASETS\n",
    "engineered_datasets = {}\n"
   ],
   "id": "5c4d7cc0f459d817",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:42:47.119634Z",
     "start_time": "2025-10-07T09:42:46.804743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CATEGORY 1: ORE CHARACTERISTICS FEATURES\n",
    "def engineer_ore_features(ore_df):\n",
    "    \"\"\"Generate ore characteristics features (Features 1-18)\"\"\"\n",
    "    print(\"\\nEngineering Ore Characteristics Features...\")\n",
    "\n",
    "    ore_data = ore_df.copy()\n",
    "\n",
    "    # Basic transformations (1-7)\n",
    "    ore_data['mn_grade_squared'] = ore_data['mn_grade_pct'] ** 2\n",
    "    ore_data['mn_grade_log'] = np.log1p(ore_data['mn_grade_pct'])\n",
    "\n",
    "    ore_data['gangue_total'] = (ore_data['fe_content_pct'] + ore_data['siO2_content_pct'] +\n",
    "                         ore_data['al2O3_content_pct'] + ore_data['p_content_pct'])\n",
    "    ore_data['ore_quality_index'] = ore_data['mn_grade_pct'] / (ore_data['gangue_total'] + 0.01)\n",
    "    ore_data['mn_to_fe_ratio'] = ore_data['mn_grade_pct'] / (ore_data['fe_content_pct'] + 0.01)\n",
    "    ore_data['mn_to_silica_ratio'] = ore_data['mn_grade_pct'] / (ore_data['siO2_content_pct'] + 0.01)\n",
    "    ore_data['valuable_mineral_ratio'] = ore_data['mn_grade_pct'] / (ore_data['mn_grade_pct'] + ore_data['gangue_total'])\n",
    "\n",
    "    # Derived features (8-12)\n",
    "    ore_data['ore_hardness_category'] = pd.cut(ore_data['work_index_kwh_t'],\n",
    "                                         bins=[0, 12, 15, 18, 25],\n",
    "                                         labels=['soft', 'medium', 'hard', 'very_hard'])\n",
    "\n",
    "    ore_data['liberation_difficulty'] = ore_data['work_index_kwh_t'] * ore_data['p80_mm']\n",
    "    ore_data['density_grade_product'] = ore_data['specific_gravity'] * ore_data['mn_grade_pct']\n",
    "    ore_data['moisture_adjusted_grade'] = ore_data['mn_grade_pct'] * (100 - ore_data['moisture_pct']) / 100\n",
    "\n",
    "    max_possible_grade = 52.0\n",
    "    ore_data['enrichment_potential'] = (max_possible_grade - ore_data['mn_grade_pct']) / ore_data['mn_grade_pct']\n",
    "\n",
    "    # Ore type encoding (13-14)\n",
    "    ore_type_dummies = pd.get_dummies(ore_data['ore_type'], prefix='ore_type')\n",
    "    ore_data = pd.concat([ore_data, ore_type_dummies], axis=1)\n",
    "\n",
    "    processability_map = {'oxide': 0.7, 'carbonate': 0.85, 'silicate': 0.9}\n",
    "    ore_data['ore_processability_score'] = ore_data['ore_type'].map(processability_map)\n",
    "    ore_data['ore_processability_score'] *= (ore_data['mn_grade_pct'] / 50) * (1 / (ore_data['work_index_kwh_t'] / 15))\n",
    "\n",
    "    # Statistical features (15-18)\n",
    "    mean_grade = ore_data['mn_grade_pct'].mean()\n",
    "    ore_data['grade_deviation_from_mean'] = ore_data['mn_grade_pct'] - mean_grade\n",
    "    ore_data['grade_percentile_rank'] = ore_data['mn_grade_pct'].rank(pct=True)\n",
    "    ore_data['is_high_grade'] = (ore_data['mn_grade_pct'] > 60).astype(int)\n",
    "    ore_data['is_low_grade'] = (ore_data['mn_grade_pct'] < 45).astype(int)\n",
    "\n",
    "    print(f\"  Generated {len([c for c in ore_data.columns if c not in ore_df.columns])} ore features\")\n",
    "    return ore_data\n",
    "\n",
    "\n",
    "engineered_datasets['ore_feed_engineered'] = engineer_ore_features(datasets['ore_feed'])"
   ],
   "id": "da59e05781c81d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Engineering Ore Characteristics Features...\n",
      "  Generated 20 ore features\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:42:53.356941Z",
     "start_time": "2025-10-07T09:42:52.204472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#SAVING ENGINEERED DATASETS TO ENGINEERED_DATA DIRECTORY INSIDE THE DATA DIRECTORY.\n",
    "# Base project directory\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# New directory path for engineered datasets (this will create a folder named 'engineered_data' inside 'data/')\n",
    "engineered_data = os.path.join(base_dir, \"data\", \"engineered_data\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(engineered_data, exist_ok=True)\n",
    "\n",
    "print(f\"Engineered datasets will be saved in: {engineered_data}\")\n",
    "\n",
    "for name, df in engineered_datasets.items():\n",
    "    save_path = os.path.join(engineered_data, f\"{name}.csv\")\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved {name} to {save_path}\")\n"
   ],
   "id": "5f6eb2fd20c68ca1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered datasets will be saved in: /home/darlenewendie/PycharmProjects/Intelligent-Manganese-Processing-Plant-Optimization/data/engineered_data\n",
      "Saved ore_feed_engineered to /home/darlenewendie/PycharmProjects/Intelligent-Manganese-Processing-Plant-Optimization/data/engineered_data/ore_feed_engineered.csv\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "manganese_venv",
   "language": "python",
   "display_name": "Manganese Processing (venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
